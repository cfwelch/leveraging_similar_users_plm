#!/bin/bash
#SBATCH --job-name=anchor-user-embedding-awd-lstm-lm-train-on-subset-20000
#SBATCH --mail-user=chenxgu@umich.edu
#SBATCH --mail-type=BEGIN,END
#SBATCH --time=100:00:00
#SBATCH --account=mihalcea1
#SBATCH --gres=gpu:1
#SBATCH --partition=gpu
#SBATCH --output=/home/chenxgu/personalized_language_modeling/scripts/anchor-user-embedding-awd-lstm-lm-train-on-subset/output.txt
#SBATCH --nodes=1
#SBATCH --mem-per-cpu=8g

#cd /home/chenxgu
export PATH=/home/chenxgu/anaconda3/bin:$PATH
source ../../../.bashrc
conda activate pytorch04
python main.py --lr 3 --num_training_token_per_user 20000  --users_type anchor_users --data ../../data/250000_tokens_of_anchor_users --pretrained_token_embedding '../GloVe-1.2-emsize-200/GloVe_200' --freeze_parameters --token_emsize 200 --user_emsize 50 --batch_size 20 --dropouti 0.2 --dropouth 0.2 --dropout 0.2 --dropoute 0.1 --seed 20190930 --epoch 200 --save model_1_20000.pt > model_1_20000.log
